# å¥–åŠ±é…ç½®çŠ¶æ€æ£€æŸ¥

## å½“å‰é…ç½®çŠ¶æ€

### 1. config.yaml ä¸­çš„åŸºç¡€å¥–åŠ±é…ç½® âœ…

```yaml
training:
  ready_reward: 0.1            # å¬ç‰Œå¥–åŠ±
  hu_reward: 1.0               # èƒ¡ç‰Œå¥–åŠ±
  flower_pig_penalty: -5.0     # èŠ±çŒªæƒ©ç½š
  final_score_weight: 1.0      # æœ€ç»ˆå¾—åˆ†æƒé‡
```

**çŠ¶æ€**ï¼šâœ… å·²é…ç½®

### 2. è¯¾ç¨‹å­¦ä¹ é…ç½® âš ï¸

```yaml
curriculum_learning:
  enabled: false               # âš ï¸ è¯¾ç¨‹å­¦ä¹ æœªå¯ç”¨
```

**çŠ¶æ€**ï¼šâš ï¸ **æœªå¯ç”¨**

**å½±å“**ï¼š
- å¦‚æœ `curriculum_learning.enabled = false`ï¼Œ`initial_reward_config = {}`ï¼ˆç©ºå­—å…¸ï¼‰
- `RewardShaping` ä¼šä½¿ç”¨ç©ºçš„ `reward_config = {}`
- åœ¨ `compute_step_reward` ä¸­ï¼Œå¦‚æœ `reward_config` æ˜¯ç©ºçš„ï¼Œå¾ˆå¤šå¥–åŠ±é¡¹æ— æ³•è®¡ç®—

### 3. RewardShaping çš„é»˜è®¤è¡Œä¸º

æŸ¥çœ‹ `reward_shaping.py` çš„ `compute_step_reward` æ–¹æ³•ï¼š

```python
def compute_step_reward(
    self,
    is_ready: bool = False,
    is_hu: bool = False,
    is_flower_pig: bool = False,
    shanten: Optional[int] = None,
    previous_shanten: Optional[int] = None,
    ...
) -> float:
    reward = 0.0
    
    # å¦‚æœä½¿ç”¨é˜¶æ®µç‰¹å®šçš„å¥–åŠ±é…ç½®
    if self.reward_config.get('raw_score_only', False):
        return 0.0
    
    # å®šç¼ºç›¸å…³å¥–åŠ±ï¼ˆé˜¶æ®µ1ï¼‰
    if lack_color_discard:
        reward += self.reward_config.get('lack_color_discard', 0.0)  # âš ï¸ å¦‚æœ reward_config æ˜¯ç©ºçš„ï¼Œè¿”å› 0.0
    
    # å‘å¬æ•°å¥–åŠ±ï¼ˆé˜¶æ®µ2-4ï¼‰
    shanten_weight = self.reward_config.get('shanten_reward', self.shanten_reward_weight if self.use_shanten_reward else 0.0)
    # âš ï¸ å¦‚æœ reward_config æ˜¯ç©ºçš„ï¼Œä¸” use_shanten_reward=Falseï¼Œshanten_weight = 0.0
    
    # å¬ç‰Œå¥–åŠ±ï¼ˆå¦‚æœæœªåœ¨å‘å¬æ•°å¥–åŠ±ä¸­å¤„ç†ï¼‰
    if is_ready and shanten_weight == 0:
        reward += self.reward_config.get('ready_reward', self.ready_reward)  # âœ… ä¼šä½¿ç”¨ self.ready_reward (0.1)
    
    # èƒ¡ç‰Œå¥–åŠ±ï¼ˆé˜¶æ®µ3+ï¼‰
    if is_hu:
        reward += self.reward_config.get('base_win', self.hu_reward)  # âœ… ä¼šä½¿ç”¨ self.hu_reward (1.0)
    
    # èŠ±çŒªæƒ©ç½š
    if is_flower_pig:
        reward += self.reward_config.get('flower_pig_penalty', self.flower_pig_penalty)  # âœ… ä¼šä½¿ç”¨ self.flower_pig_penalty (-5.0)
```

**åˆ†æ**ï¼š
- âœ… **åŸºç¡€å¥–åŠ±ä¼šç”Ÿæ•ˆ**ï¼š`is_ready`ã€`is_hu`ã€`is_flower_pig` ä¼šä½¿ç”¨ `self.ready_reward`ã€`self.hu_reward`ã€`self.flower_pig_penalty`
- âš ï¸ **é˜¶æ®µç‰¹å®šå¥–åŠ±ä¸ä¼šç”Ÿæ•ˆ**ï¼šå¦‚æœ `reward_config` æ˜¯ç©ºçš„ï¼Œ`lack_color_discard`ã€`shanten_reward` ç­‰ä¼šè¿”å› 0.0
- âš ï¸ **å‘å¬æ•°å¥–åŠ±ä¸ä¼šç”Ÿæ•ˆ**ï¼šå¦‚æœ `reward_config` æ˜¯ç©ºçš„ï¼Œä¸” `use_shanten_reward=False`ï¼Œå‘å¬æ•°å¥–åŠ±ä¸ä¼šè®¡ç®—

## é—®é¢˜è¯Šæ–­

### å¦‚æœæ‰€æœ‰å¥–åŠ±éƒ½æ˜¯ 0ï¼Œå¯èƒ½çš„åŸå› ï¼š

1. **æ¸¸æˆæµå±€**ï¼šæ²¡æœ‰ç©å®¶èƒ¡ç‰Œï¼Œ`is_hu=False`ï¼Œ`final_score=0.0`
2. **ç©å®¶æœªå¬ç‰Œ**ï¼š`is_ready=False`ï¼Œä¸”æ²¡æœ‰å‘å¬æ•°å¥–åŠ±
3. **ç©å®¶æœªæˆä¸ºèŠ±çŒª**ï¼š`is_flower_pig=False`
4. **reward_config ä¸ºç©º**ï¼šé˜¶æ®µç‰¹å®šå¥–åŠ±ï¼ˆå¦‚å‘å¬æ•°å¥–åŠ±ï¼‰æ— æ³•è®¡ç®—

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šå¯ç”¨è¯¾ç¨‹å­¦ä¹ ï¼ˆæ¨èï¼‰

ä¿®æ”¹ `config.yaml`ï¼š

```yaml
curriculum_learning:
  enabled: true                # âœ… å¯ç”¨è¯¾ç¨‹å­¦ä¹ 
  initial_stage: declare_suit  # ä»å®šç¼ºé˜¶æ®µå¼€å§‹
```

**ä¼˜ç‚¹**ï¼š
- è‡ªåŠ¨é…ç½®å„é˜¶æ®µçš„å¥–åŠ±æƒé‡
- æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒæ•´å¥–åŠ±
- æä¾›æ›´ä¸°å¯Œçš„å¥–åŠ±ä¿¡å·

**ç¼ºç‚¹**ï¼š
- éœ€è¦è¯¾ç¨‹å­¦ä¹ æ¨¡å—æ”¯æŒ

### æ–¹æ¡ˆ 2ï¼šæ‰‹åŠ¨é…ç½® reward_config

åœ¨ `train.py` ä¸­æ‰‹åŠ¨è®¾ç½® `reward_config`ï¼š

```python
# å¦‚æœæ²¡æœ‰è¯¾ç¨‹å­¦ä¹ ï¼Œä½¿ç”¨é»˜è®¤çš„ reward_config
if not curriculum:
    initial_reward_config = {
        'ready_reward': 0.1,      # å¬ç‰Œå¥–åŠ±
        'base_win': 1.0,          # èƒ¡ç‰Œå¥–åŠ±
        'flower_pig_penalty': -5.0, # èŠ±çŒªæƒ©ç½š
        'shanten_reward': 0.05,    # å‘å¬æ•°å¥–åŠ±æƒé‡ï¼ˆå¯é€‰ï¼‰
        'shanten_decrease': 2.0,   # å‘å¬æ•°å‡å°‘å¥–åŠ±ï¼ˆå¯é€‰ï¼‰
        'shanten_increase': -1.5,  # å‘å¬æ•°å¢åŠ æƒ©ç½šï¼ˆå¯é€‰ï¼‰
    }
else:
    initial_reward_config = curriculum.get_current_reward_config()

reward_shaping = RewardShaping(
    ready_reward=training_config.get('ready_reward', 0.1),
    hu_reward=training_config.get('hu_reward', 1.0),
    flower_pig_penalty=training_config.get('flower_pig_penalty', -5.0),
    final_score_weight=training_config.get('final_score_weight', 1.0),
    reward_config=initial_reward_config,
)
```

### æ–¹æ¡ˆ 3ï¼šæ£€æŸ¥æ¸¸æˆæ˜¯å¦æ­£å¸¸ç»“æŸ

æ·»åŠ æ—¥å¿—ï¼Œæ£€æŸ¥æ¸¸æˆæµå±€çš„æ¯”ä¾‹ï¼š

```python
# åœ¨ worker.py ä¸­æ·»åŠ 
if trajectory['final_score'] == 0.0:
    print(f"Worker {self.worker_id}, Game {game_id}: Game ended with final_score=0.0 (å¯èƒ½æµå±€)")
```

## å½“å‰çŠ¶æ€æ€»ç»“

### âœ… å·²é…ç½®
- `config.yaml` ä¸­çš„åŸºç¡€å¥–åŠ±å‚æ•°ï¼ˆ`ready_reward`, `hu_reward`, `flower_pig_penalty`, `final_score_weight`ï¼‰
- `RewardShaping` ä¼šä½¿ç”¨è¿™äº›åŸºç¡€å‚æ•°

### âš ï¸ æœªé…ç½®
- `curriculum_learning.enabled = false`ï¼Œæ‰€ä»¥ `reward_config = {}`
- é˜¶æ®µç‰¹å®šå¥–åŠ±ï¼ˆå¦‚å‘å¬æ•°å¥–åŠ±ï¼‰æ— æ³•ä½¿ç”¨
- å¦‚æœæ¸¸æˆæµå±€æˆ–ç©å®¶æœªå¬ç‰Œ/æœªèƒ¡ç‰Œï¼Œå¥–åŠ±å¯èƒ½ä¸º 0

### ğŸ” éœ€è¦ç¡®è®¤
1. æ¸¸æˆæ˜¯å¦æ­£å¸¸ç»“æŸï¼ˆæœ‰ç©å®¶èƒ¡ç‰Œï¼‰ï¼Ÿ
2. ç©å®¶æ˜¯å¦å¬ç‰Œï¼ˆ`is_ready=True`ï¼‰ï¼Ÿ
3. ç©å®¶æ˜¯å¦èƒ¡ç‰Œï¼ˆ`is_hu=True`ï¼‰ï¼Ÿ
4. æœ€ç»ˆå¾—åˆ†æ˜¯å¦æ­£ç¡®æå–ï¼ˆ`final_score != 0.0`ï¼‰ï¼Ÿ

## å»ºè®®

1. **é¦–å…ˆæ£€æŸ¥æ¸¸æˆæ˜¯å¦æ­£å¸¸ç»“æŸ**ï¼šæ·»åŠ æ—¥å¿—ï¼Œç»Ÿè®¡æ¸¸æˆæµå±€çš„æ¯”ä¾‹
2. **å¦‚æœæ¸¸æˆæµå±€æ¯”ä¾‹é«˜**ï¼šè€ƒè™‘å¯ç”¨è¯¾ç¨‹å­¦ä¹ æˆ–æ·»åŠ å‘å¬æ•°å¥–åŠ±
3. **å¦‚æœæ¸¸æˆæ­£å¸¸ç»“æŸä½†å¥–åŠ±ä»ä¸º 0**ï¼šæ£€æŸ¥ `is_ready`ã€`is_hu`ã€`is_flower_pig` çš„å€¼
4. **å¦‚æœåŸºç¡€å¥–åŠ±åº”è¯¥ç”Ÿæ•ˆä½†æœªç”Ÿæ•ˆ**ï¼šæ£€æŸ¥ `reward_config` ä¼ é€’æ˜¯å¦æ­£ç¡®

