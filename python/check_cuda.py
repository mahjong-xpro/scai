#!/usr/bin/env python3
"""
CUDA è¯Šæ–­è„šæœ¬

æ£€æŸ¥ CUDA å’Œ GPU çš„å¯ç”¨æ€§ï¼Œå¸®åŠ©è¯Šæ–­ PyTorch CUDA é—®é¢˜ã€‚
"""

import os
import sys

print("=" * 60)
print("CUDA è¯Šæ–­ä¿¡æ¯")
print("=" * 60)

# 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
print("\n1. ç¯å¢ƒå˜é‡æ£€æŸ¥:")
cuda_visible = os.environ.get("CUDA_VISIBLE_DEVICES", "not set")
print(f"   CUDA_VISIBLE_DEVICES: {cuda_visible}")

# 2. æ¸…é™¤å¯èƒ½æ— æ•ˆçš„ç¯å¢ƒå˜é‡
if "CUDA_VISIBLE_DEVICES" in os.environ:
    print("   æ¸…é™¤ CUDA_VISIBLE_DEVICES...")
    del os.environ["CUDA_VISIBLE_DEVICES"]

# 3. æ£€æŸ¥ PyTorch
print("\n2. PyTorch CUDA æ£€æŸ¥:")
try:
    import torch
    print(f"   PyTorch version: {torch.__version__}")
    print(f"   CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDA version (PyTorch): {torch.version.cuda}")
        print(f"   cuDNN version: {torch.backends.cudnn.version()}")
        print(f"   GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("   âš ï¸  PyTorch æ— æ³•æ£€æµ‹åˆ° CUDA")
        print("   å¯èƒ½çš„åŸå› :")
        print("     - PyTorch æ˜¯ç”¨ CPU-only ç‰ˆæœ¬å®‰è£…çš„")
        print("     - PyTorch CUDA ç‰ˆæœ¬ä¸ç³»ç»Ÿ CUDA é©±åŠ¨ä¸åŒ¹é…")
        print("     - CUDA é©±åŠ¨æœªæ­£ç¡®å®‰è£…")
        
except Exception as e:
    print(f"   âŒ å¯¼å…¥ PyTorch æ—¶å‡ºé”™: {e}")

# 4. æ£€æŸ¥ç³»ç»Ÿ CUDA å’Œé©±åŠ¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
print("\n3. ç³»ç»Ÿ CUDA å’Œé©±åŠ¨æ£€æŸ¥:")
try:
    import subprocess
    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
    if result.returncode == 0:
        print("   nvidia-smi è¾“å‡º:")
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
        lines = result.stdout.split('\n')
        for i, line in enumerate(lines):
            if i < 15:  # æ˜¾ç¤ºå‰15è¡Œ
                print(f"   {line}")
            elif "Driver Version" in line or "CUDA Version" in line:
                print(f"   {line}")
        
        # æå–é©±åŠ¨ç‰ˆæœ¬å’Œ CUDA ç‰ˆæœ¬
        driver_version = None
        cuda_version = None
        for line in lines:
            if "Driver Version:" in line:
                parts = line.split("Driver Version:")
                if len(parts) > 1:
                    driver_version = parts[1].strip().split()[0]
            if "CUDA Version:" in line:
                parts = line.split("CUDA Version:")
                if len(parts) > 1:
                    cuda_version = parts[1].strip().split()[0]
        
        if driver_version:
            print(f"\n   ğŸ“Š é©±åŠ¨ç‰ˆæœ¬: {driver_version}")
            print(f"   ğŸ“Š é©±åŠ¨æ”¯æŒçš„æœ€é«˜ CUDA ç‰ˆæœ¬: {cuda_version}")
            
            # æ£€æŸ¥é©±åŠ¨ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚
            try:
                driver_major = int(driver_version.split('.')[0])
                if driver_major < 450:
                    print(f"   âš ï¸  é©±åŠ¨ç‰ˆæœ¬å¯èƒ½å¤ªæ—§ï¼ˆ{driver_version}ï¼‰ï¼Œå»ºè®® >= 450.xx")
                elif driver_major < 525:
                    print(f"   âš ï¸  é©±åŠ¨ç‰ˆæœ¬å¯èƒ½è¾ƒæ—§ï¼ˆ{driver_version}ï¼‰ï¼ŒPyTorch CUDA 12.x å»ºè®® >= 525.xx")
                elif driver_major < 535:
                    print(f"   âš ï¸  é©±åŠ¨ç‰ˆæœ¬ï¼ˆ{driver_version}ï¼‰ï¼ŒPyTorch CUDA 12.8 å»ºè®® >= 535.xx")
                else:
                    print(f"   âœ“ é©±åŠ¨ç‰ˆæœ¬çœ‹èµ·æ¥è¶³å¤Ÿæ–°")
            except:
                pass
    else:
        print("   âš ï¸  nvidia-smi å‘½ä»¤å¤±è´¥")
except FileNotFoundError:
    print("   âš ï¸  nvidia-smi å‘½ä»¤æœªæ‰¾åˆ°")
except subprocess.TimeoutExpired:
    print("   âš ï¸  nvidia-smi å‘½ä»¤è¶…æ—¶")
except Exception as e:
    print(f"   âš ï¸  æ£€æŸ¥ nvidia-smi æ—¶å‡ºé”™: {e}")

# 5. ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
print("\n4. ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥:")
try:
    import torch
    if torch.cuda.is_available():
        pytorch_cuda = torch.version.cuda
        print(f"   PyTorch CUDA ç‰ˆæœ¬: {pytorch_cuda}")
        
        # æ£€æŸ¥ CUDA å·¥å…·åŒ…ç‰ˆæœ¬
        try:
            result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=3)
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    if 'release' in line.lower():
                        print(f"   ç³»ç»Ÿ CUDA å·¥å…·åŒ…: {line.strip()}")
        except:
            pass
    else:
        print("   âš ï¸  æ— æ³•æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆCUDA ä¸å¯ç”¨ï¼‰")
except:
    pass

# 6. å»ºè®®
print("\n5. å»ºè®®:")
try:
    import torch
    if not torch.cuda.is_available():
        print("   å¦‚æœ nvidia-smi æ˜¾ç¤º GPU ä½† PyTorch æ£€æµ‹ä¸åˆ°ï¼Œå¯èƒ½çš„åŸå› ï¼š")
        print("   1. âš ï¸  é©±åŠ¨ç‰ˆæœ¬é—®é¢˜ï¼ˆæœ€å¯èƒ½ï¼‰:")
        print("      - æ£€æŸ¥é©±åŠ¨ç‰ˆæœ¬: nvidia-smi | grep 'Driver Version'")
        print("      - PyTorch CUDA 12.8 éœ€è¦é©±åŠ¨ >= 535.xx")
        print("      - PyTorch CUDA 12.1 éœ€è¦é©±åŠ¨ >= 525.xx")
        print("      - å¦‚æœé©±åŠ¨å¤ªæ—§ï¼Œéœ€è¦æ›´æ–°é©±åŠ¨")
        print("   2. PyTorch CUDA ç‰ˆæœ¬ä¸é©±åŠ¨ä¸åŒ¹é…:")
        print("      - æ£€æŸ¥: python -c 'import torch; print(torch.version.cuda)'")
        print("      - é‡æ–°å®‰è£…åŒ¹é…çš„ PyTorch ç‰ˆæœ¬")
        print("   3. æš‚æ—¶ä½¿ç”¨ CPU è®­ç»ƒ:")
        print("      - åœ¨ config.yaml ä¸­è®¾ç½® gpu.enabled: false")
except:
    pass

print("\n" + "=" * 60)

