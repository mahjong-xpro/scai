#!/usr/bin/env python3
"""
é˜¶æ®µ1è®­ç»ƒæ£€æŸ¥è„šæœ¬

ç”¨æ³•:
    python scripts/check_stage1.py [--log-dir <æ—¥å¿—ç›®å½•>]
    
ç¤ºä¾‹:
    python scripts/check_stage1.py
    python scripts/check_stage1.py --log-dir ./logs
"""

import argparse
import re
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict


def parse_log_file(log_file):
    """è§£ææ—¥å¿—æ–‡ä»¶"""
    results = {
        'stage': None,
        'reward_config': {},
        'trajectories': [],
        'losses': [],
        'iterations': [],
        'validation_stats': [],
        'errors': [],
    }
    
    try:
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            lines = content.split('\n')
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        return results
    
    # æ£€æŸ¥é˜¶æ®µä¿¡æ¯
    if "å®šç¼ºé˜¶æ®µ" in content or "DECLARE_SUIT" in content:
        results['stage'] = "é˜¶æ®µ1ï¼ˆå®šç¼ºä¸ç”Ÿå­˜ï¼‰"
    
    # æå–å¥–åŠ±é…ç½®
    reward_config_match = re.search(r"Reward config for stage.*?:\s*({[^}]+})", content)
    if reward_config_match:
        try:
            config_str = reward_config_match.group(1)
            # ç®€å•çš„å­—å…¸è§£æ
            for key, value in re.findall(r"'(\w+)':\s*([-\d.]+)", config_str):
                results['reward_config'][key] = float(value)
        except:
            pass
    
    # æå–è½¨è¿¹æ•°é‡
    for match in re.finditer(r'num_trajectories=(\d+)', content):
        results['trajectories'].append(int(match.group(1)))
    
    # æå–è®­ç»ƒæŸå¤±
    for match in re.finditer(
        r'Training step \d+ \(iteration=(\d+), policy_loss=([-\d.]+), value_loss=([-\d.]+), entropy_loss=([-\d.]+), total_loss=([-\d.]+)\)',
        content
    ):
        iteration = int(match.group(1))
        policy_loss = float(match.group(2))
        value_loss = float(match.group(3))
        entropy_loss = float(match.group(4))
        total_loss = float(match.group(5))
        results['losses'].append({
            'iteration': iteration,
            'policy_loss': policy_loss,
            'value_loss': value_loss,
            'entropy_loss': entropy_loss,
            'total_loss': total_loss,
        })
        results['iterations'].append(iteration)
    
    # æå–éªŒè¯ç»Ÿè®¡
    for match in re.finditer(
        r'Valid trajectories: (\d+).*?Invalid trajectories: (\d+).*?Valid rate: ([\d.]+)%',
        content,
        re.DOTALL
    ):
        results['validation_stats'].append({
            'valid': int(match.group(1)),
            'invalid': int(match.group(2)),
            'valid_rate': float(match.group(3)),
        })
    
    # æå–é”™è¯¯ä¿¡æ¯
    error_patterns = [
        r'Error: ([^\n]+)',
        r'Warning: ([^\n]+)',
        r'Failed: ([^\n]+)',
    ]
    for pattern in error_patterns:
        for match in re.finditer(pattern, content):
            results['errors'].append(match.group(1))
    
    return results


def check_stage1_training(log_dir="./logs"):
    """æ£€æŸ¥é˜¶æ®µ1è®­ç»ƒæ•ˆæœ"""
    log_dir = Path(log_dir)
    
    if not log_dir.exists():
        print(f"âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_dir}")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ—¥å¿—
    log_files = sorted(log_dir.glob("training_*.log"), reverse=True)
    
    if not log_files:
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶: {log_dir}/training_*.log")
        return
    
    latest_log = log_files[0]
    print("=" * 60)
    print(f"ğŸ“„ æ£€æŸ¥æ—¥å¿—: {latest_log.name}")
    print(f"ğŸ“… ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(latest_log.stat().st_mtime)}")
    print("=" * 60)
    print()
    
    # è§£ææ—¥å¿—
    results = parse_log_file(latest_log)
    
    # 1. æ£€æŸ¥é˜¶æ®µä¿¡æ¯
    print("1ï¸âƒ£  é˜¶æ®µä¿¡æ¯")
    if results['stage']:
        print(f"   âœ… å½“å‰é˜¶æ®µ: {results['stage']}")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°é˜¶æ®µ1ä¿¡æ¯ï¼Œå¯èƒ½å·²è¿›å…¥å…¶ä»–é˜¶æ®µ")
    print()
    
    # 2. æ£€æŸ¥å¥–åŠ±é…ç½®
    print("2ï¸âƒ£  å¥–åŠ±é…ç½®")
    if results['reward_config']:
        print("   âœ… å¥–åŠ±é…ç½®:")
        for key, value in results['reward_config'].items():
            print(f"      - {key}: {value}")
        
        # æ£€æŸ¥å…³é”®å¥–åŠ±
        if 'lack_color_discard' in results['reward_config']:
            print("   âœ… åŒ…å« lack_color_discardï¼ˆæ‰“ç¼ºé—¨ç‰Œå¥–åŠ±ï¼‰")
        else:
            print("   âš ï¸  æœªæ‰¾åˆ° lack_color_discard å¥–åŠ±é…ç½®")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°å¥–åŠ±é…ç½®ä¿¡æ¯")
    print()
    
    # 3. æ£€æŸ¥æ•°æ®æ”¶é›†
    print("3ï¸âƒ£  æ•°æ®æ”¶é›†")
    if results['trajectories']:
        latest_trajectories = results['trajectories'][-1]
        print(f"   âœ… æœ€æ–°æ•°æ®æ”¶é›†: {latest_trajectories} æ¡è½¨è¿¹")
        
        if len(results['trajectories']) > 1:
            first = results['trajectories'][0]
            last = results['trajectories'][-1]
            if last > first:
                print(f"   âœ… è½¨è¿¹æ•°é‡åœ¨å¢é•¿: {first} -> {last}")
            else:
                print(f"   âš ï¸  è½¨è¿¹æ•°é‡æœªå¢é•¿: {first} -> {last}")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°æ•°æ®æ”¶é›†ä¿¡æ¯")
    print()
    
    # 4. æ£€æŸ¥éªŒè¯ç»Ÿè®¡
    print("4ï¸âƒ£  æ•°æ®éªŒè¯")
    if results['validation_stats']:
        latest = results['validation_stats'][-1]
        valid_rate = latest['valid_rate']
        print(f"   âœ… æœ€æ–°éªŒè¯ç»Ÿè®¡:")
        print(f"      - æœ‰æ•ˆè½¨è¿¹: {latest['valid']}")
        print(f"      - æ— æ•ˆè½¨è¿¹: {latest['invalid']}")
        print(f"      - æœ‰æ•ˆç‡: {valid_rate:.2f}%")
        
        if valid_rate >= 90:
            print("   âœ… æœ‰æ•ˆç‡è‰¯å¥½ï¼ˆ>= 90%ï¼‰")
        elif valid_rate >= 70:
            print("   âš ï¸  æœ‰æ•ˆç‡ä¸€èˆ¬ï¼ˆ70-90%ï¼‰")
        else:
            print("   âŒ æœ‰æ•ˆç‡è¾ƒä½ï¼ˆ< 70%ï¼‰")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°éªŒè¯ç»Ÿè®¡ä¿¡æ¯")
    print()
    
    # 5. æ£€æŸ¥è®­ç»ƒæŸå¤±
    print("5ï¸âƒ£  è®­ç»ƒæŸå¤±")
    if results['losses']:
        if len(results['losses']) >= 2:
            first_loss = results['losses'][0]
            last_loss = results['losses'][-1]
            
            print(f"   ğŸ“Š æŸå¤±å˜åŒ–:")
            print(f"      - ç­–ç•¥æŸå¤±: {first_loss['policy_loss']:.4f} -> {last_loss['policy_loss']:.4f}")
            print(f"      - ä»·å€¼æŸå¤±: {first_loss['value_loss']:.4f} -> {last_loss['value_loss']:.4f}")
            print(f"      - æ€»æŸå¤±: {first_loss['total_loss']:.4f} -> {last_loss['total_loss']:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸‹é™
            policy_improved = abs(last_loss['policy_loss']) < abs(first_loss['policy_loss'])
            value_improved = last_loss['value_loss'] < first_loss['value_loss']
            total_improved = last_loss['total_loss'] < first_loss['total_loss']
            
            if policy_improved:
                print("   âœ… ç­–ç•¥æŸå¤±åœ¨ä¸‹é™")
            else:
                print("   âš ï¸  ç­–ç•¥æŸå¤±æœªä¸‹é™")
            
            if value_improved:
                print("   âœ… ä»·å€¼æŸå¤±åœ¨ä¸‹é™")
            else:
                print("   âš ï¸  ä»·å€¼æŸå¤±æœªä¸‹é™")
            
            if total_improved:
                print("   âœ… æ€»æŸå¤±åœ¨ä¸‹é™")
            else:
                print("   âš ï¸  æ€»æŸå¤±æœªä¸‹é™")
        else:
            print(f"   âš ï¸  æŸå¤±æ•°æ®ä¸è¶³ï¼ˆåªæœ‰ {len(results['losses'])} æ¡è®°å½•ï¼‰")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæŸå¤±ä¿¡æ¯")
    print()
    
    # 6. æ£€æŸ¥è¿­ä»£è¿›åº¦
    print("6ï¸âƒ£  è®­ç»ƒè¿›åº¦")
    if results['iterations']:
        latest_iteration = max(results['iterations'])
        print(f"   âœ… æœ€æ–°è¿­ä»£: {latest_iteration}")
        
        if latest_iteration < 2000:
            print("   âš ï¸  è¿­ä»£æ¬¡æ•°ä¸è¶³ï¼ˆ< 2000ï¼‰ï¼Œé˜¶æ®µ1è‡³å°‘éœ€è¦2000æ¬¡è¿­ä»£")
        elif latest_iteration >= 8000:
            print("   âš ï¸  è¿­ä»£æ¬¡æ•°å·²è¶…è¿‡8000ï¼Œåº”è¯¥æ¨è¿›åˆ°é˜¶æ®µ2")
        else:
            print(f"   âœ… è¿­ä»£è¿›åº¦æ­£å¸¸ï¼ˆ{latest_iteration}/8000ï¼‰")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°è¿­ä»£ä¿¡æ¯")
    print()
    
    # 7. æ£€æŸ¥é”™è¯¯
    print("7ï¸âƒ£  é”™è¯¯æ£€æŸ¥")
    if results['errors']:
        unique_errors = list(set(results['errors'][-20:]))  # æœ€è¿‘20ä¸ªé”™è¯¯
        print(f"   âš ï¸  å‘ç° {len(results['errors'])} ä¸ªé”™è¯¯/è­¦å‘Š")
        if len(unique_errors) <= 5:
            print("   ğŸ“‹ æœ€è¿‘çš„é”™è¯¯:")
            for error in unique_errors[:5]:
                print(f"      - {error[:80]}...")
        else:
            print(f"   ğŸ“‹ æœ€è¿‘çš„é”™è¯¯ï¼ˆæ˜¾ç¤ºå‰5ä¸ªï¼‰:")
            for error in unique_errors[:5]:
                print(f"      - {error[:80]}...")
    else:
        print("   âœ… æœªå‘ç°é”™è¯¯")
    print()
    
    # æ€»ç»“
    print("=" * 60)
    print("ğŸ“‹ æ£€æŸ¥æ€»ç»“")
    print("=" * 60)
    
    checks = []
    if results['stage']:
        checks.append("âœ… é˜¶æ®µä¿¡æ¯æ­£ç¡®")
    if 'lack_color_discard' in results['reward_config']:
        checks.append("âœ… å¥–åŠ±é…ç½®æ­£ç¡®")
    if results['trajectories']:
        checks.append("âœ… æ•°æ®æ”¶é›†æ­£å¸¸")
    if results['losses'] and len(results['losses']) >= 2:
        first = results['losses'][0]
        last = results['losses'][-1]
        if last['total_loss'] < first['total_loss']:
            checks.append("âœ… è®­ç»ƒæŸå¤±ä¸‹é™")
    
    if checks:
        print("\n".join(checks))
        print("\nğŸ‰ é˜¶æ®µ1è®­ç»ƒçœ‹èµ·æ¥æ­£å¸¸ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥é¡¹æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°è¯¦ç»†ä¿¡æ¯")
    print()


def main():
    parser = argparse.ArgumentParser(
        description='æ£€æŸ¥é˜¶æ®µ1è®­ç»ƒæ•ˆæœ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--log-dir',
        default='./logs',
        help='æ—¥å¿—ç›®å½•ï¼ˆé»˜è®¤: ./logsï¼‰'
    )
    
    args = parser.parse_args()
    check_stage1_training(args.log_dir)


if __name__ == '__main__':
    main()

